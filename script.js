const btnEscuchar = document.getElementById('btn-escuchar');
const status = document.getElementById('status');
const rostro = document.getElementById('rostro');

const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
recognition.lang = 'es-MX';

const synth = window.speechSynthesis;

function hablar(texto) {
    synth.cancel();
    const utterance = new SpeechSynthesisUtterance(texto);
    utterance.lang = 'es-MX';
    utterance.onstart = () => { rostro.innerText = "üòÆ"; };
    utterance.onend = () => { rostro.innerText = "üòä"; };
    synth.speak(utterance);
}

btnEscuchar.addEventListener('click', () => {
    try {
        recognition.start();
        status.innerText = "Escuchando...";
        rostro.innerText = "üëÇ";
    } catch (e) { console.log("Reconocimiento ya activo"); }
});

recognition.onresult = async (event) => {
    const textoEscuchado = event.results[0][0].transcript;
    status.innerText = "Dijiste: " + textoEscuchado;
    
    const respuestaIA = await preguntarAGemini(textoEscuchado);
    hablar(respuestaIA);
};

async function preguntarAGemini(textoUsuario) {
    status.innerText = "Pensando...";
    rostro.innerText = "ü§î";

    try {
        const respuesta = await fetch('/api/chat', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ prompt: textoUsuario })
        });

        const datos = await respuesta.json();
        return datos.reply || "No recib√≠ respuesta.";

    } catch (error) {
        status.innerText = "Error de conexi√≥n.";
        rostro.innerText = "üòµ";
        return "Mi conexi√≥n fall√≥. Por favor, revisa los logs en el panel de Vercel.";
    }
}
