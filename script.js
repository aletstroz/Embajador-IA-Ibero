const btnEscuchar = document.getElementById('btn-escuchar');
const status = document.getElementById('status');
const rostro = document.getElementById('rostro');

// CONFIGURACI칍N DE VOZ (O칤do)
const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
recognition.lang = 'es-MX';
recognition.interimResults = false;

// CONFIGURACI칍N DE VOZ (Hablar)
const synth = window.speechSynthesis;

function hablar(texto) {
    synth.cancel(); // Detener cualquier audio previo
    const utterance = new SpeechSynthesisUtterance(texto);
    utterance.lang = 'es-MX';
    
    utterance.onstart = () => { rostro.innerText = "游땵"; };
    utterance.onend = () => { rostro.innerText = "游땕"; };
    
    synth.speak(utterance);
}

// ACTIVAR MICR칍FONO
btnEscuchar.addEventListener('click', () => {
    try {
        recognition.start();
        status.innerText = "Escuchando...";
        rostro.innerText = "游녝";
    } catch (e) {
        console.log("El micr칩fono ya est치 activo.");
    }
});

// PROCESAR RESULTADO
recognition.onresult = async (event) => {
    const textoEscuchado = event.results[0][0].transcript;
    status.innerText = "Dijiste: " + textoEscuchado;
    
    const respuestaIA = await preguntarAGemini(textoEscuchado);
    hablar(respuestaIA);
};

// LLAMADA AL SERVIDOR
async function preguntarAGemini(textoUsuario) {
    status.innerText = "Pensando...";
    rostro.innerText = "游뱂";

    try {
        const respuesta = await fetch('/api/chat', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ prompt: textoUsuario })
        });

        const datos = await respuesta.json();
        return datos.reply || "No recib칤 una respuesta v치lida.";

    } catch (error) {
        console.error("Error de conexi칩n:", error);
        status.innerText = "Error de red.";
        rostro.innerText = "游땻";
        return "Hubo un fallo en la conexi칩n con mi servidor.";
    }
}
